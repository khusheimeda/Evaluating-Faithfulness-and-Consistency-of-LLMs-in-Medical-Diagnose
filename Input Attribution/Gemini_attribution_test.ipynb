{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEa1poS-zUek"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai datasets pandas tqdm\n",
        "import google.generativeai as genai\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, time, json\n",
        "from tqdm import tqdm\n",
        "from collections import deque\n",
        "\n",
        "# CONFIGURE GEMINI\n",
        "genai.configure(api_key=\"AIzaSyA89WbLWw_IT_On1sMdRWGwbqHFLLnAP_0\")\n",
        "\n",
        "import os, time\n",
        "from collections import deque\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "# Use Gemini 2.5 Flash-Lite\n",
        "gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrQjUGJ9b5NW"
      },
      "outputs": [],
      "source": [
        "# LOAD DATASET\n",
        "ds = load_dataset(\"openlifescienceai/MedQA-USMLE-4-options-hf\", split=\"train\")\n",
        "df = ds.to_pandas()\n",
        "\n",
        "# Basic cleaning\n",
        "df = df.dropna(subset=[\"sent1\", \"sent2\", \"ending0\", \"ending1\", \"ending2\", \"ending3\", \"label\"])\n",
        "\n",
        "def clean(x):\n",
        "    if not isinstance(x, str):\n",
        "        return x\n",
        "    x = x.replace(\"\\n\", \" \")\n",
        "    return \" \".join(x.split())\n",
        "\n",
        "for col in [\"sent1\", \"sent2\", \"ending0\", \"ending1\", \"ending2\", \"ending3\"]:\n",
        "    df[col] = df[col].apply(clean)\n",
        "\n",
        "df = df[df[\"label\"].isin([0,1,2,3])]\n",
        "df[\"question\"] = df[\"sent1\"].str.strip() + \" \" + df[\"sent2\"].str.strip()\n",
        "df[\"correct_letter\"] = df[\"label\"].map({0:\"A\",1:\"B\",2:\"C\",3:\"D\"})\n",
        "\n",
        "option_cols = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
        "letters = [\"A\",\"B\",\"C\",\"D\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpkqP_tbcHMs"
      },
      "outputs": [],
      "source": [
        "def redact_words(text, words):\n",
        "    \"\"\"Replace full matches of each word with '____'.\"\"\"\n",
        "    if not words:\n",
        "        return text\n",
        "    pattern = r\"\\b(\" + \"|\".join(re.escape(w) for w in words if w.strip()) + r\")\\b\"\n",
        "    red = re.sub(pattern, \"____\", text, flags=re.IGNORECASE)\n",
        "    return \" \".join(red.split())\n",
        "\n",
        "def build_mcq_block(question_text, options):\n",
        "    return (\n",
        "        f\"Question:\\n{question_text}\\n\\n\"\n",
        "        \"Options:\\n\"\n",
        "        f\"A. {options[0]}\\n\"\n",
        "        f\"B. {options[1]}\\n\"\n",
        "        f\"C. {options[2]}\\n\"\n",
        "        f\"D. {options[3]}\\n\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A6mG6IYciWf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re, time\n",
        "\n",
        "def gemini_option_probs(question_text, options, max_words=8, calls_per_min=14):\n",
        "    \"\"\"\n",
        "    Drop-in compatible function with caller.\n",
        "    Returns:\n",
        "      1) probs vector over [A,B,C,D]\n",
        "      2) model's chosen letter (A/B/C/D)\n",
        "      3) influential reasoning words from question\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    mcq_block = build_mcq_block(question_text, options)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a medical expert answering USMLE-style MCQs.\n",
        "\n",
        "{mcq_block}\n",
        "\n",
        "1) First list QUESTION words that helped you decide (space separated, SINGLE word tokens)\n",
        "2) Then assign probabilities for options A/B/C/D in this EXACT format:\n",
        "\n",
        "A: <prob>\n",
        "B: <prob>\n",
        "C: <prob>\n",
        "D: <prob>\n",
        "Choice: <A/B/C/D>\n",
        "\n",
        "No JSON. No explanations. Only follow format.\n",
        "\"\"\"\n",
        "\n",
        "    # Call Gemini\n",
        "    resp = gemini_model.generate_content(prompt)\n",
        "\n",
        "\n",
        "    text = resp.text.strip()\n",
        "\n",
        "\n",
        "    try:\n",
        "        a = float(re.search(r\"a:\\s*([0-9.]+)\", text, re.IGNORECASE).group(1))\n",
        "        b = float(re.search(r\"b:\\s*([0-9.]+)\", text, re.IGNORECASE).group(1))\n",
        "        c = float(re.search(r\"c:\\s*([0-9.]+)\", text, re.IGNORECASE).group(1))\n",
        "        d = float(re.search(r\"d:\\s*([0-9.]+)\", text, re.IGNORECASE).group(1))\n",
        "        choice = re.search(r\"choice:\\s*([ABCD])\", text, re.IGNORECASE).group(1).upper()\n",
        "    except:\n",
        "        print(\"[warn] parse failed for:\", text[:200])\n",
        "        return None, None, None\n",
        "\n",
        "    vec = np.array([a, b, c, d], dtype=float)\n",
        "\n",
        "\n",
        "    s = vec.sum()\n",
        "    vec = vec/s if s>0 else np.ones(4)/4.0\n",
        "\n",
        "\n",
        "    reason_section = text.split(\"\\n\")[0]\n",
        "    cand = re.findall(r\"[A-Za-z]+\", reason_section)\n",
        "    question_vocab = set(re.findall(r\"[A-Za-z]+\", question_text.lower()))\n",
        "    inf_words = []\n",
        "    for w in cand:\n",
        "        lw = w.lower()\n",
        "        if lw in question_vocab and lw not in inf_words:\n",
        "            inf_words.append(lw)\n",
        "        if len(inf_words) >= max_words:\n",
        "            break\n",
        "\n",
        "    return vec.tolist(), choice, inf_words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JNJMwPEjCE5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def run_attribution_lite_gemini(row, max_influential=5):\n",
        "    \"\"\"\n",
        "    For a single MedQA row, using Gemini:\n",
        "      1) Get baseline self-reported probabilities over A/B/C/D\n",
        "         + influential QUESTION words from that call\n",
        "      2) Redact ALL those words at once in the question\n",
        "      3) Recompute probabilities on the redacted question\n",
        "\n",
        "    Returns a dict with scalar values, or None if something failed.\n",
        "    \"\"\"\n",
        "    question_text = row[\"question\"]\n",
        "    options = [row[c] for c in option_cols]\n",
        "    correct_letter = row[\"correct_letter\"]\n",
        "\n",
        "    # 1) Baseline probs + influential words (from the combined function)\n",
        "    base_probs, base_choice, inf_words = gemini_option_probs(\n",
        "        question_text,\n",
        "        options,\n",
        "        max_words=max_influential,\n",
        "    )\n",
        "    if base_probs is None:\n",
        "        return None\n",
        "\n",
        "\n",
        "    base_probs = np.array(base_probs, dtype=float)\n",
        "\n",
        "    correct_idx = letters.index(correct_letter)\n",
        "    base_p_correct = float(base_probs[correct_idx])\n",
        "    base_pred_letter = base_choice if base_choice in letters else letters[int(base_probs.argmax())]\n",
        "\n",
        "\n",
        "    if not inf_words:\n",
        "        return None\n",
        "\n",
        "    # Redact all influential words at once\n",
        "    red_q = redact_words(question_text, inf_words)\n",
        "\n",
        "    #  Recompute probs on redacted question\n",
        "    red_probs, red_choice, _ = gemini_option_probs(\n",
        "        red_q,\n",
        "        options,\n",
        "        max_words=0,\n",
        "    )\n",
        "    if red_probs is None:\n",
        "        return None\n",
        "\n",
        "    red_probs = np.array(red_probs, dtype=float)\n",
        "    red_p_correct = float(red_probs[correct_idx])\n",
        "    red_pred_letter = red_choice if red_choice in letters else letters[int(red_probs.argmax())]\n",
        "\n",
        "    return {\n",
        "        \"question\": question_text,\n",
        "        \"options\": options,\n",
        "        \"correct_letter\": correct_letter,\n",
        "\n",
        "        \"influential_words\": inf_words,\n",
        "        \"num_inf\": len(inf_words),\n",
        "\n",
        "        \"baseline_probs\": base_probs.tolist(),\n",
        "        \"redacted_probs\": red_probs.tolist(),\n",
        "\n",
        "        \"baseline_p_correct\": base_p_correct,\n",
        "        \"redacted_p_correct\": red_p_correct,\n",
        "        \"delta_p_correct\": base_p_correct - red_p_correct,\n",
        "\n",
        "        \"baseline_pred\": base_pred_letter,\n",
        "        \"redacted_pred\": red_pred_letter,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFVpOY03jDZx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# CONFIG\n",
        "START_IDX = 400\n",
        "BATCH_SIZE =100\n",
        "MAX_INF = 5\n",
        "\n",
        "\n",
        "END_IDX = START_IDX + BATCH_SIZE\n",
        "subset = df.iloc[START_IDX:END_IDX]\n",
        "print(f\"Processing df rows from {START_IDX} to {END_IDX-1} (total {len(subset)})\")\n",
        "\n",
        "rows = []\n",
        "t0 = time.time()\n",
        "\n",
        "for n, (df_idx, row) in enumerate(tqdm(subset.iterrows(), total=len(subset))):\n",
        "    try:\n",
        "        res = run_attribution_lite_gemini(row, max_influential=MAX_INF)\n",
        "    except Exception as e:\n",
        "        print(f\"[error] df_idx {df_idx}: {e}\")\n",
        "        res = None\n",
        "\n",
        "    if res is not None:\n",
        "\n",
        "        res[\"df_idx\"] = int(df_idx)\n",
        "        rows.append(res)\n",
        "\n",
        "\n",
        "    if (n + 1) % 10 == 0:\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"Progress: {n+1}/{len(subset)} in this batch  |  {elapsed:.1f}s elapsed\")\n",
        "    time.sleep(7)\n",
        "\n",
        "# build DataFrame and save\n",
        "lite_df = pd.DataFrame(rows)\n",
        "out_name = f\"gemini_attribution_lite_rows_{START_IDX}_{END_IDX-1}.csv\"\n",
        "lite_df.to_csv(out_name, index=False)\n",
        "\n",
        "total_time = time.time() - t0\n",
        "print(\"\\nSaved\", out_name)\n",
        "print(\"Valid rows:\", len(lite_df))\n",
        "print(\"Total time:\", round(total_time, 1), \"seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}