{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEA4bSPZTIWz"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai datasets pandas\n",
        "\n",
        "import google.generativeai as genai\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time, re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjp4WCtlTaeP",
        "outputId": "df174e4b-053c-483b-fbc6-e56d94c08117"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10178"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#GEMINI CONFIG\n",
        "API_KEY = \"AIzaSyD143Azp4v6HKR4WLP2cHXDPWQjvneRMm4\"\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "\n",
        "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
        "gemini_model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "#LOAD DATA\n",
        "ds = load_dataset(\"openlifescienceai/MedQA-USMLE-4-options-hf\", split=\"train\")\n",
        "df = ds.to_pandas()\n",
        "\n",
        "# Build full question text\n",
        "df[\"question\"] = df[\"sent1\"].str.strip() + \" \" + df[\"sent2\"].str.strip()\n",
        "\n",
        "option_cols = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
        "letters = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "len(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oHsbThPTcmL"
      },
      "outputs": [],
      "source": [
        "\n",
        "RPM_LIMIT = 15\n",
        "SAFETY_FACTOR = 0.8\n",
        "MIN_INTERVAL = 60.0 / (RPM_LIMIT * SAFETY_FACTOR)\n",
        "\n",
        "last_call_time = 0.0\n",
        "\n",
        "def rate_limited_generate(prompt: str):\n",
        "    \"\"\"\n",
        "    Wrapper around gemini_model.generate_content that enforces a minimum\n",
        "    delay between requests so we don't exceed RPM.\n",
        "    \"\"\"\n",
        "    global last_call_time\n",
        "    now = time.time()\n",
        "    wait = MIN_INTERVAL - (now - last_call_time)\n",
        "    if wait > 0:\n",
        "        time.sleep(wait)\n",
        "    last_call_time = time.time()\n",
        "    return gemini_model.generate_content(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOWzdguTd_2"
      },
      "outputs": [],
      "source": [
        "def ask_gemini_mcq(question_text: str, options):\n",
        "    \"\"\"\n",
        "    question_text: full question (no options embedded)\n",
        "    options: [ending0, ending1, ending2, ending3] -> A,B,C,D\n",
        "    returns: 'A'/'B'/'C'/'D' or None\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are solving a 4-option USMLE-style medical multiple choice question.\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Options:\n",
        "A. {options[0]}\n",
        "B. {options[1]}\n",
        "C. {options[2]}\n",
        "D. {options[3]}\n",
        "\n",
        "Reply with ONLY the single letter of the correct choice: A, B, C, or D.\n",
        "Do NOT include any explanation or extra text.\n",
        "\"\"\"\n",
        "    resp = rate_limited_generate(prompt)\n",
        "    text = (resp.text or \"\").strip().upper()\n",
        "    m = re.search(r\"[ABCD]\", text)\n",
        "    return m.group(0) if m else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uNuPE3XTf3y"
      },
      "outputs": [],
      "source": [
        "def paraphrase_with_gemini(question: str) -> str:\n",
        "    prompt = f\"\"\"Paraphrase the following USMLE-style medical MCQ question.\n",
        "\n",
        "Rules:\n",
        "1. Keep the original meaning exactly the same.\n",
        "2. Do NOT solve the question.\n",
        "3. Do NOT include answer choices.\n",
        "4. Only rewrite the question text clearly and concisely.\n",
        "5. Preserve medical terminology.\n",
        "\n",
        "Question to paraphrase:\n",
        "{question}\n",
        "\"\"\"\n",
        "    resp = rate_limited_generate(prompt)\n",
        "    return (resp.text or \"\").strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOQUdQWsT2fh"
      },
      "outputs": [],
      "source": [
        "# Drop obvious junk\n",
        "df = df.dropna(subset=[\"sent1\", \"sent2\", \"ending0\", \"ending1\", \"ending2\", \"ending3\", \"label\"])\n",
        "\n",
        "#  Normalize whitespace\n",
        "def clean(x):\n",
        "    if not isinstance(x, str): return x\n",
        "    x = x.replace(\"\\n\", \" \")\n",
        "    return \" \".join(x.split())\n",
        "\n",
        "for col in [\"sent1\", \"sent2\", \"ending0\", \"ending1\", \"ending2\", \"ending3\"]:\n",
        "    df[col] = df[col].apply(clean)\n",
        "\n",
        "df = df[df[\"label\"].isin([0,1,2,3])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SJJXXUJThWE"
      },
      "outputs": [],
      "source": [
        "#  BATCH CONFIG\n",
        "TOTAL_QUESTIONS = len(df)\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "BATCH_ID   = 7\n",
        "\n",
        "SEED = 42\n",
        "rng = np.random.default_rng(SEED)\n",
        "all_indices = rng.permutation(TOTAL_QUESTIONS)\n",
        "\n",
        "start = BATCH_ID * BATCH_SIZE\n",
        "end   = min(start + BATCH_SIZE, TOTAL_QUESTIONS)\n",
        "\n",
        "batch_indices = all_indices[start:end]\n",
        "subset = df.iloc[batch_indices].copy().reset_index(drop=True)\n",
        "\n",
        "print(f\"Total questions: {TOTAL_QUESTIONS}\")\n",
        "print(f\"Processing batch {BATCH_ID}: indices [{start}:{end}) -> size = {len(subset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxCriEE0TpYb"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "correct_orig = 0\n",
        "correct_para = 0\n",
        "consistant=0\n",
        "\n",
        "N_SAMPLES = len(subset)\n",
        "\n",
        "for i, (_, row) in enumerate(subset.iterrows(), start=1):\n",
        "    question = row[\"question\"]\n",
        "    options = [row[c] for c in option_cols]\n",
        "    true_label_idx = int(row[\"label\"])\n",
        "    true_letter = letters[true_label_idx]\n",
        "\n",
        "    #  Gemini on ORIGINAL question + options\n",
        "    pred_orig = ask_gemini_mcq(question, options)\n",
        "\n",
        "    # Paraphrase question with Gemini\n",
        "    para_question = paraphrase_with_gemini(question)\n",
        "\n",
        "    #  Gemini on PARAPHRASED question + same options\n",
        "    pred_para = ask_gemini_mcq(para_question, options)\n",
        "\n",
        "    # Track accuracy\n",
        "    if pred_orig == true_letter:\n",
        "        correct_orig += 1\n",
        "    if pred_para == true_letter:\n",
        "        correct_para += 1\n",
        "    if pred_orig==pred_para:\n",
        "      consistant+=1\n",
        "\n",
        "\n",
        "\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"paraphrased_question\": para_question,\n",
        "        \"A\": options[0],\n",
        "        \"B\": options[1],\n",
        "        \"C\": options[2],\n",
        "        \"D\": options[3],\n",
        "        \"true_letter\": true_letter,\n",
        "        \"pred_original\": pred_orig,\n",
        "        \"pred_paraphrased\": pred_para,\n",
        "    })\n",
        "\n",
        "\n",
        "    if i % 10 == 0 or i == N_SAMPLES:\n",
        "        print(f\"Processed {i}/{N_SAMPLES}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1GbxYqTrVL"
      },
      "outputs": [],
      "source": [
        "orig_acc = correct_orig / N_SAMPLES\n",
        "para_acc = correct_para / N_SAMPLES\n",
        "consist=consistant/N_SAMPLES\n",
        "\n",
        "print(f\"\\nBatch {BATCH_ID} â€“ Samples: {N_SAMPLES}\")\n",
        "print(f\"Accuracy (original question):    {orig_acc:.3f}\")\n",
        "print(f\"Accuracy (paraphrased question): {para_acc:.3f}\")\n",
        "print(f\"Consistency : {consist:.3f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "out_name = f\"medqa_gemini_eval_batch_{BATCH_ID}.csv\"\n",
        "results_df.to_csv(out_name, index=False)\n",
        "print(\"Saved:\", out_name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}